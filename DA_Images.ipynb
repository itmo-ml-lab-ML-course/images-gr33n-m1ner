{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Парсер"
   ],
   "metadata": {
    "id": "-5w5mc7tt1Cl"
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import lxml.html as l\n",
    "import requests\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.models import resnet50\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from torchvision import models\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "id": "lq3eAa4Lutwy",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "97cf0175-cc15-4f93-d13a-39569ec4dd19",
    "ExecuteTime": {
     "end_time": "2024-03-14T08:37:04.076033500Z",
     "start_time": "2024-03-14T08:36:58.819770100Z"
    }
   },
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "CARS_BROWSE_LINK = 'https://cars.usnews.com/cars-trucks/browse?sort=Alphabetical'\n",
    "CARS_CLASS = 'Image__PictureImage-sc-412cjc-1 ilGKlg Image-sc-412cjc-2 DetailCardCarFinder__ProductImage-sc-18gh3vl-10 kQDDcT lnNlgK'\n",
    "\n",
    "HEADER = {\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'Accept-Language': 'en-US,en;q=0.9',\n",
    "    'Sec-Ch-Ua': '\"Not A(Brand\";v=\"99\", \"Opera\";v=\"107\", \"Chromium\";v=\"121\"',\n",
    "    'Sec-Ch-Ua-Mobile': '?0',\n",
    "    'Sec-Ch-Ua-Platform': \"Windows\",\n",
    "    'Sec-Fetch-Dest': 'document',\n",
    "    'Sec-Fetch-Mode': 'navigate',\n",
    "    'Sec-Fetch-Site': 'same-origin',\n",
    "    'Sec-Fetch-User': '?1',\n",
    "    'Upgrade-Insecure-Requests': '1',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 OPR/107.0.0.0',\n",
    "}\n",
    "\n",
    "SAMPLE_SIZE = 500\n",
    "\n",
    "def clone(element):\n",
    "    return l.fromstring(l.tostring(element))\n",
    "\n",
    "def parse_cars():\n",
    "    data = []\n",
    "    page = 1\n",
    "    ind = 1\n",
    "    while len(data) < SAMPLE_SIZE:\n",
    "        current_link = CARS_BROWSE_LINK + \"&page=\" + str(page)\n",
    "        request = requests.get(current_link, headers=HEADER)\n",
    "        document = l.fromstring(request.text)\n",
    "\n",
    "        for card in document.find_class(CARS_CLASS):\n",
    "            card = clone(card)\n",
    "            image = requests.get(card.get(\"src\"), headers=HEADER)\n",
    "            name = 'dataset_cars/output_image' + str(ind) + '.png'\n",
    "            with open(name, 'wb') as file:\n",
    "                file.write(image.content)\n",
    "            ind += 1\n",
    "            entry = [name, card.get(\"src\"), \"car\"]\n",
    "            data.append(entry)\n",
    "            if len(data) >= SAMPLE_SIZE:\n",
    "                break\n",
    "        page += 1\n",
    "        print(len(data))\n",
    "    return data\n",
    "\n",
    "def save_data_cars():\n",
    "    data = parse_cars()\n",
    "    df = pd.DataFrame(data, columns=['Name', 'Link', 'Class'])\n",
    "    df.to_csv('cars_data.csv', index=False)\n",
    "\n",
    "save_data_cars()"
   ],
   "metadata": {
    "id": "4BaIHyLOCeJB"
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "120\n",
      "140\n",
      "160\n",
      "180\n",
      "200\n",
      "220\n",
      "240\n",
      "260\n",
      "280\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "def get_motorcycle_link(n):\n",
    "    return \"https://spb.x-m.su/mototehnika/motocikly?PAGEN_2=\" + str(n)\n",
    "SITE='https://spb.x-m.su'\n",
    "\n",
    "MOTORCYCLE_SAMPLE_SIZE = 300\n",
    "\n",
    "def parse_motorcycles():\n",
    "    data = []\n",
    "    page = 1\n",
    "    ind = 1\n",
    "    while len(data) < MOTORCYCLE_SAMPLE_SIZE:\n",
    "        current_link = get_motorcycle_link(page)\n",
    "        request = requests.get(current_link)\n",
    "        document = l.fromstring(request.text)\n",
    "        \n",
    "        for card in document.find_class(\"catalog_section_list_img_slider\"):\n",
    "            link = SITE + card.getchildren()[0].getchildren()[0].get(\"data-src\")\n",
    "            image = requests.get(link)\n",
    "            name = 'dataset_motorcycles/output_image' + str(ind) + '.png'\n",
    "            with open(name, 'wb') as file:\n",
    "                file.write(image.content)\n",
    "            ind += 1\n",
    "            entry = [name, link, \"motorcycle\"]\n",
    "            data.append(entry)\n",
    "            if len(data) >= MOTORCYCLE_SAMPLE_SIZE:\n",
    "                break\n",
    "        page += 1\n",
    "        print(len(data))\n",
    "    return data\n",
    "\n",
    "def save_data_motorcycles():\n",
    "    data = parse_motorcycles()\n",
    "    df = pd.DataFrame(data, columns=['Name', 'Link', 'Class'])\n",
    "    df.to_csv('motorcycles_data.csv', index=False)\n",
    "\n",
    "save_data_motorcycles()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T09:42:02.548214200Z",
     "start_time": "2024-03-14T09:39:23.103475600Z"
    }
   },
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def one_hot(s):\n",
    "    if s == \"car\":\n",
    "        return 0\n",
    "    return 1\n",
    "    \n",
    "def get_tensor(name):\n",
    "    image = Image.open(name)\n",
    "    image = image.resize((224, 224))\n",
    "    if image.mode == 'RGBA':\n",
    "        image = image.convert('RGB')\n",
    "    tensor = TF.to_tensor(image)\n",
    "    tensor = tensor / 255\n",
    "    return transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))(tensor)\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.tensors = list(map(get_tensor, data[\"Name\"]))\n",
    "        self.classes = list(map(one_hot, data[\"Class\"]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.classes)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.tensors[index], self.classes[index]\n",
    "    \n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.names = list(data[\"Name\"])\n",
    "        self.classes = list(map(one_hot, data[\"Class\"]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.classes)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        im = Image.open(self.names[index])\n",
    "        im = im.resize((224, 224))\n",
    "        tensor = TF.pil_to_tensor(im)\n",
    "        tensor = tensor / 255\n",
    "        tensor = transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))(tensor)\n",
    "        return tensor, self.classes[index]\n",
    "    \n",
    "def delete_bad_objects(data, indexes):\n",
    "    for ind in indexes:\n",
    "        data = data[~data[\"Name\"].str.contains('output_image' + str(ind) + '.png')]\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T09:47:08.542028400Z",
     "start_time": "2024-03-14T09:47:08.365846Z"
    }
   },
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "DATA1 = pd.read_csv(\"cars_data.csv\")\n",
    "DATA2 = pd.read_csv(\"motorcycles_data.csv\")\n",
    "DATA2 = delete_bad_objects(DATA2, [164, 293, 296])\n",
    "DATA = pd.concat([DATA1, DATA2], ignore_index=True)\n",
    "\n",
    "data_train, data_test = train_test_split(DATA, test_size=0.2)\n",
    "train_dataset = TrainDataset(data_train)\n",
    "test_dataset = TrainDataset(data_test)\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T09:58:48.049869400Z",
     "start_time": "2024-03-14T09:58:42.841183600Z"
    }
   },
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "CarClassifier(\n  (model): ResNet(\n    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU(inplace=True)\n    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (layer1): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (4): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (5): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n  )\n  (fc1): Sequential(\n    (0): Linear(in_features=1000, out_features=32, bias=True)\n    (1): ReLU()\n  )\n  (fc2): Sequential(\n    (0): Dropout(p=0.2, inplace=False)\n    (1): Linear(in_features=32, out_features=2, bias=True)\n  )\n)"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CarClassifier(nn.Module):\n",
    "    def __init__(self, classes):\n",
    "        super(CarClassifier, self).__init__()\n",
    "        self.model = resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(1000, 32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.fc1(self.model(x)))\n",
    "    \n",
    "CLASSES_SIZE = 2\n",
    "MODEL = CarClassifier(CLASSES_SIZE)\n",
    "MODEL.to(DEVICE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T09:58:51.488260600Z",
     "start_time": "2024-03-14T09:58:51.265499800Z"
    }
   },
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "source": [
    "def train(model, epochs, lr):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_hist = []\n",
    "    acc_hist = []\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        running_loss = 0\n",
    "        running_acc = 0\n",
    "        \n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x) \n",
    "            _, predicted = torch.max(y_pred.data, 1)\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            running_acc += accuracy_score(y, predicted) \n",
    "            loss_hist.append(loss.item())\n",
    "            acc_hist.append(accuracy_score(y, predicted))\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = running_acc / len(train_loader)\n",
    "        \n",
    "        print(f'Epoch {epoch}')\n",
    "        print(f'Train Loss: {epoch_loss}, train accuracy: {epoch_acc}')\n",
    "\n",
    "\n",
    "train(MODEL, epochs=15, lr=0.0001)"
   ],
   "metadata": {
    "id": "tn2hARNDNGTw",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6639a29b-0f98-4eee-e8cb-cae302990bcb",
    "ExecuteTime": {
     "end_time": "2024-03-14T10:07:25.590705900Z",
     "start_time": "2024-03-14T09:59:46.886270900Z"
    }
   },
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train Loss: 0.6081145746367318, train accuracy: 0.8182625482625482\n",
      "Epoch 2\n",
      "Train Loss: 0.5542648094041007, train accuracy: 0.8961389961389961\n",
      "Epoch 3\n",
      "Train Loss: 0.5128189197608403, train accuracy: 0.9041312741312743\n",
      "Epoch 4\n",
      "Train Loss: 0.4729328879288265, train accuracy: 0.9102702702702702\n",
      "Epoch 5\n",
      "Train Loss: 0.43299668601581026, train accuracy: 0.9274131274131274\n",
      "Epoch 6\n",
      "Train Loss: 0.39970878618104116, train accuracy: 0.9294208494208495\n",
      "Epoch 7\n",
      "Train Loss: 0.36223351529666353, train accuracy: 0.9447104247104247\n",
      "Epoch 8\n",
      "Train Loss: 0.33583122917584013, train accuracy: 0.9518532818532819\n",
      "Epoch 9\n",
      "Train Loss: 0.3054905150617872, train accuracy: 0.9537065637065636\n",
      "Epoch 10\n",
      "Train Loss: 0.2865484356880188, train accuracy: 0.9547104247104246\n",
      "Epoch 11\n",
      "Train Loss: 0.2672461760895593, train accuracy: 0.9498455598455599\n",
      "Epoch 12\n",
      "Train Loss: 0.2503055738551276, train accuracy: 0.9465637065637065\n",
      "Epoch 13\n",
      "Train Loss: 0.23037887045315333, train accuracy: 0.9622779922779923\n",
      "Epoch 14\n",
      "Train Loss: 0.21665562050683157, train accuracy: 0.9608494208494207\n",
      "Epoch 15\n",
      "Train Loss: 0.1971785511289324, train accuracy: 0.9732818532818532\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "MODEL.eval()\n",
    "def test_model(model, loader):\n",
    "    correct = 0\n",
    "    correct_f_score = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            x, y = data\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            outputs = model(x)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            correct += accuracy_score(y, predicted)\n",
    "            correct_f_score += f1_score(y, predicted, average='weighted')\n",
    "\n",
    "    print(f'Accuracy of the model: {correct / len(loader)}')\n",
    "    print(f'F-score of the model: {correct_f_score / len(loader)}')\n",
    "\n",
    "\n",
    "print(\"Test\")\n",
    "test_model(MODEL, test_loader)\n",
    "print(\"Train\")\n",
    "test_model(MODEL, train_loader)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BzD4cyGSe6Zz",
    "outputId": "d5b4bec5-a381-4e6f-faec-a4d28da6a6e7",
    "ExecuteTime": {
     "end_time": "2024-03-14T10:10:41.088075Z",
     "start_time": "2024-03-14T10:09:58.288914500Z"
    }
   },
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "Accuracy of the model: 0.9766666666666666\n",
      "F-score of the model: 0.9766048439903445\n",
      "Train\n",
      "Accuracy of the model: 0.9718532818532817\n",
      "F-score of the model: 0.9716671164604113\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
